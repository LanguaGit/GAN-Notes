{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook is an analyzed version of https://github.com/hardikbansal/CycleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imort module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import imageio \n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import time\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import .layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x, leak=0.2, name=\"lrelu\", alt_relu_impl=False):\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "        if alt_relu_impl:\n",
    "            f1 = 0.5 * (1 + leak)\n",
    "            f2 = 0.5 * (1 - leak)\n",
    "            # lrelu = 1/2 * (1 + leak) * x + 1/2 * (1 - leak) * |x|\n",
    "            return f1 * x + f2 * abs(x)\n",
    "        else:\n",
    "            return tf.maximum(x, leak*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.variable_scope()` : tf.get_variable() 을 이용하여 기존에 선언된 global variable 들을 재사용하기 위한 용도 (name 으로 group 지음)\n",
    "\n",
    "    - `tf.Variable()` : 언제나 새로운 객체 (변수) 를 생성\n",
    "    \n",
    "    - `tf.get_variable()` : 이미 존재하는 객체를 매개변수로 받을 수도 있음 $\\rightarrow$ 변수 재사용 가능\n",
    "    \n",
    "    (ref: [Tensorflow 기초](https://datascienceschool.net/view-notebook/5cbab09d777841f591a67928d7043f51/))\n",
    "    \n",
    "\n",
    "- `alternative_relu_impl` (alter_relu_implemetation) : custom version of Leaky ReLU\n",
    "\n",
    "    - leak = 0.2 $\\rightarrow$ f1 = 0.6, f2 =0.4\n",
    "    \n",
    "    - `f1 * x + f2 * abs(x)`\n",
    "        \n",
    "        - $x>0$ : x\n",
    "        \n",
    "        - $x\\le0$ : 0.2 * x\n",
    "        \n",
    "        \n",
    "- `tf.maximum(x, leak*x)` : basic Leaky ReLU\n",
    "    \n",
    "    - $x>0$ : x\n",
    "        \n",
    "    - $x\\le0$ : 0.2 * x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance Norm (Batch Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_norm(x):\n",
    "\n",
    "    with tf.variable_scope(\"instance_norm\"):\n",
    "        epsilon = 1e-5\n",
    "        mean, var = tf.nn.moments(x, [1, 2], keep_dims=True)\n",
    "        \n",
    "        scale = tf.get_variable('scale',[x.get_shape()[-1]], \n",
    "            initializer=tf.truncated_normal_initializer(mean=1.0, stddev=0.02))\n",
    "        \n",
    "        offset = tf.get_variable('offset',[x.get_shape()[-1]],initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "        out = scale*tf.div(x-mean, tf.sqrt(var+epsilon)) + offset\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.nn.moments(array, shape)` : 정해진 axis 에 맞춰서 평균 (mean), 분산 (variance) 를 계산\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([[1,2],[3,4],[5,6]], dtype=tf.float32)\n",
    "mean, variance = tf.nn.moments(x, [0])\n",
    "with tf.Session() as sess:\n",
    "    m, v = sess.run([mean, variance])\n",
    "    print(m, v)\n",
    ">>> [ 3.  4.] [ 2.66666675  2.66666675]\n",
    "```\n",
    "\n",
    ">- [ 3.  4.] : means of axis 0 $\\rightarrow$ row\n",
    ">\n",
    ">    - 3. : mean of [1, 3, 5]\n",
    ">\n",
    ">    - 4. : mean of [2, 4, 6]\n",
    ">\n",
    ">\n",
    ">- [ 2.66666675  2.66666675] : variances of axis 0 $\\rightarrow$ row\n",
    ">\n",
    ">    - 2.66666675 : variance of [1, 3, 5]\n",
    ">\n",
    ">    - 2.66666675 : variance of [2, 4, 6]\n",
    "\n",
    "\n",
    "- `scale` : multiply scaler for distribution\n",
    "\n",
    "    - change **shape** of distribution\n",
    "    \n",
    "    - $scale \\times N(\\mu, \\sigma^2)$\n",
    "    \n",
    "\n",
    "- `offset` : add intercept for distribution \n",
    "\n",
    "    - change **location** of distribution\n",
    "    \n",
    "    - $N(\\mu, \\sigma^2) + offset$\n",
    "    \n",
    "\n",
    "- `out` : change both location and shape of distribution\n",
    "\n",
    "    - $scale \\times N(\\mu, \\sigma^2) + offset$\n",
    "    \n",
    "        - **[location]** $\\mu \\rightarrow scale \\times \\mu + offset$\n",
    "        \n",
    "        - **[shape]** $\\sigma \\rightarrow scale \\times \\sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_conv2d(inputconv, o_d=64, f_h=7, f_w=7, s_h=1, s_w=1, stddev=0.02, \n",
    "                   padding=\"VALID\", name=\"conv2d\", do_norm=True, do_relu=True, relufactor=0):\n",
    "    with tf.variable_scope(name):\n",
    "        \n",
    "        conv = tf.contrib.layers.conv2d(inputconv, o_d, f_w, s_w, padding, activation_fn=None,\n",
    "                                        weights_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
    "                                        biases_initializer=tf.constant_initializer(0.0))\n",
    "        if do_norm:\n",
    "            conv = instance_norm(conv)\n",
    "#             conv = tf.contrib.layers.batch_norm(conv, decay=0.9, updates_collections=None, \n",
    "#                                                 epsilon=1e-5, scale=True, scope=\"batch_norm\")\n",
    "            \n",
    "        if do_relu:\n",
    "            if(relufactor == 0):\n",
    "                conv = tf.nn.relu(conv,\"relu\")\n",
    "            else:\n",
    "                conv = lrelu(conv, relufactor, \"lrelu\")\n",
    "\n",
    "        return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **arguments**\n",
    "\n",
    ">`inputconv` : previous layer's output\n",
    ">\n",
    ">`o_d` : number of filters\n",
    ">   \n",
    ">`f_h` , `f_w` : fiter height & width\n",
    ">   \n",
    ">`s_h` , `s_w` : stride height & width\n",
    ">    \n",
    ">`stddev` : standard deviation for weight initializer\n",
    ">    \n",
    ">`padding` : 'VALID' (0 padding) or 'SAME'\n",
    ">    \n",
    ">`do_norm` : check if batch normalization will be conducted\n",
    ">    \n",
    ">`do_relu` : check if ReLU activation function will be used\n",
    ">    \n",
    ">`relufactor` : factor for Leaky ReLU (basic ReLU if 0)\n",
    "\n",
    "\n",
    "\n",
    "- `tf.contrib.layers.conv2d()`\n",
    "\n",
    "    - `inputconv` : input vector\n",
    "    \n",
    "    - `o_d` : number of filters\n",
    "    \n",
    "    - `f_w` : filter size (width == height)\n",
    "    \n",
    "    - `s_h` : stride size (width == height)\n",
    "    \n",
    "    - `activation_fn` : define activation function (defined as `None` due to batch normalization)\n",
    "    \n",
    "    - `weights_initializer`\n",
    "    \n",
    "        - `tf.truncated_normal_initializer(stddev)` : use truncated normal distribution for initialization  \n",
    "       \n",
    "    - `biases_initializer`\n",
    "    \n",
    "        - `tf.constant_initializer(0.0)` : initialize bias as constant (better be initializing as 0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De-Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_deconv2d(inputconv, outshape, o_d=64, f_h=7, f_w=7, s_h=1, s_w=1, stddev=0.02, \n",
    "                     padding=\"VALID\", name=\"deconv2d\", do_norm=True, do_relu=True, relufactor=0):\n",
    "    with tf.variable_scope(name):\n",
    "\n",
    "        conv = tf.contrib.layers.conv2d_transpose(inputconv, o_d, [f_h, f_w], [s_h, s_w], padding, \n",
    "                                                  activation_fn=None,\n",
    "                                                  weights_initializer=\n",
    "                                                  tf.truncated_normal_initializer(stddev=stddev),\n",
    "                                                  biases_initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "        if do_norm:\n",
    "            conv = instance_norm(conv)\n",
    "#             conv = tf.contrib.layers.batch_norm(conv, decay=0.9, updates_collections=None, \n",
    "#                                                 epsilon=1e-5, scale=True, scope=\"batch_norm\")\n",
    "            \n",
    "        if do_relu:\n",
    "            if(relufactor == 0):\n",
    "                conv = tf.nn.relu(conv,\"relu\")\n",
    "            else:\n",
    "                conv = lrelu(conv, relufactor, \"lrelu\")\n",
    "\n",
    "        return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **arguments**\n",
    "\n",
    "> `outshape` : define output shape (NOT USED)\n",
    "    \n",
    "\n",
    "\n",
    "- `tf.contrib.layers.conv2d_transpose()`\n",
    "\n",
    "    - **<span style=\"color: blue\">transpose</span>**\n",
    "\n",
    "    - `o_d` : output dimension (number of filters)\n",
    "\n",
    "    - `[f_h, f_w]` : shape of filter\n",
    "    \n",
    "    - `[s_h, s_w]` : shape for stride\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import .model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### constants\n",
    "\n",
    "- `img_height = 256` : height of input image\n",
    "\n",
    "- `img_width = 256` : width of input image\n",
    "    \n",
    "- `img_layer = 3` : channels (RGB) of input image\n",
    "\n",
    "- `img_size = img_height * img_width`\n",
    "\n",
    "- `batch_size = 1` : mini batch size??\n",
    "\n",
    "- `pool_size = 50` : number of pooling filters\n",
    "\n",
    "- `ngf = 32` : number of filters for generator $G$\n",
    "\n",
    "- `ndf = 64` : numbe of filters for discriminator $D$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet_block(inputres, dim, name=\"resnet\"):\n",
    "    \n",
    "    with tf.variable_scope(name):\n",
    "\n",
    "        out_res = tf.pad(inputres, [[0, 0], [1, 1], [1, 1], [0, 0]], \"REFLECT\")\n",
    "        out_res = general_conv2d(out_res, dim, 3, 3, 1, 1, 0.02, \"VALID\",\"c1\")\n",
    "        out_res = tf.pad(out_res, [[0, 0], [1, 1], [1, 1], [0, 0]], \"REFLECT\")\n",
    "        out_res = general_conv2d(out_res, dim, 3, 3, 1, 1, 0.02, \"VALID\",\"c2\",do_relu=False)\n",
    "        \n",
    "        return tf.nn.relu(out_res + inputres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **arguments**\n",
    "\n",
    "> `inputres` : output of previous resnet block\n",
    ">\n",
    "> `dim` : filter size for convolution layer\n",
    "\n",
    "\n",
    "\n",
    "- `tf.pad(tensor, paddings, mode='CONSTANT')`\n",
    "\n",
    "```python\n",
    "t = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "paddings = tf.constant([[1, 1,], [2, 2]])\n",
    "\n",
    "tf.pad(t, paddings, \"CONSTANT\")  # [[0, 0, 0, 0, 0, 0, 0],\n",
    "                                 #  [0, 0, 1, 2, 3, 0, 0],\n",
    "                                 #  [0, 0, 4, 5, 6, 0, 0],\n",
    "                                 #  [0, 0, 0, 0, 0, 0, 0]]\n",
    "\n",
    "tf.pad(t, paddings, \"REFLECT\")  # [[6, 5, 4, 5, 6, 5, 4],\n",
    "                                #  [3, 2, 1, 2, 3, 2, 1],\n",
    "                                #  [6, 5, 4, 5, 6, 5, 4],\n",
    "                                #  [3, 2, 1, 2, 3, 2, 1]]\n",
    "```\n",
    "\n",
    "> - padding will be added to this two dimensional array\n",
    ">\n",
    "> ```python\n",
    "> t = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    ">\n",
    "> [[1, 2, 3] \n",
    ">  [4, 5, 6]]\n",
    "> ```\n",
    "> \n",
    "> - `paddings = tf.constant([[1, 1,], [2, 2]])`\n",
    ">\n",
    ">     - [padding_**top**, padding_**bottom**], [padding_**left**, padding_**right**] : 위, 아래, 양옆 으로 얼마만큼 붙일지 설정\n",
    ">\n",
    ">\n",
    "> - `mode`\n",
    ">\n",
    ">     - 어떤 숫자를 padding 할지 방법 설정\n",
    ">\n",
    ">     - 'CONSTANT' : 정해진 숫자 하나로 채움 (default = 0) ([0, 0, <span style=\"color: blue\">1, 2, 3</span>, 0, 0])\n",
    ">    \n",
    ">     - 'REFLECT' : 기존 데이터의 패턴을 반복하는 방식 ([3, 2, <span style=\"color: blue\">1, 2, 3</span>, 2, 1])\n",
    "\n",
    "\n",
    "\n",
    "- `general_conv2d()` : user defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator $G$ : ResNet block $\\times$ 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator_resnet_6blocks(inputgen, name=\"generator\"):\n",
    "    with tf.variable_scope(name):\n",
    "        f = 7\n",
    "        ks = 3\n",
    "        \n",
    "        pad_input = tf.pad(inputgen,[[0, 0], [ks, ks], [ks, ks], [0, 0]], \"REFLECT\")\n",
    "        o_c1 = general_conv2d(pad_input, ngf, f, f, 1, 1, 0.02,name=\"c1\")\n",
    "        o_c2 = general_conv2d(o_c1, ngf*2, ks, ks, 2, 2, 0.02,\"SAME\",\"c2\")\n",
    "        o_c3 = general_conv2d(o_c2, ngf*4, ks, ks, 2, 2, 0.02,\"SAME\",\"c3\")\n",
    "\n",
    "        o_r1 = build_resnet_block(o_c3, ngf*4, \"r1\")\n",
    "        o_r2 = build_resnet_block(o_r1, ngf*4, \"r2\")\n",
    "        o_r3 = build_resnet_block(o_r2, ngf*4, \"r3\")\n",
    "        o_r4 = build_resnet_block(o_r3, ngf*4, \"r4\")\n",
    "        o_r5 = build_resnet_block(o_r4, ngf*4, \"r5\")\n",
    "        o_r6 = build_resnet_block(o_r5, ngf*4, \"r6\")\n",
    "\n",
    "        o_c4 = general_deconv2d(o_r6, [batch_size,64,64,ngf*2], ngf*2, ks, ks, 2, 2, 0.02,\"SAME\",\"c4\")\n",
    "        o_c5 = general_deconv2d(o_c4, [batch_size,128,128,ngf], ngf, ks, ks, 2, 2, 0.02,\"SAME\",\"c5\")\n",
    "        o_c5_pad = tf.pad(o_c5,[[0, 0], [ks, ks], [ks, ks], [0, 0]], \"REFLECT\")\n",
    "        o_c6 = general_conv2d(o_c5_pad, img_layer, f, f, 1, 1, 0.02,\"VALID\",\"c6\",do_relu=False)\n",
    "\n",
    "        # Adding the tanh layer\n",
    "\n",
    "        out_gen = tf.nn.tanh(o_c6,\"t1\")\n",
    "\n",
    "\n",
    "        return out_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **constants**\n",
    "\n",
    "> `f` : input layer filter size (width == height)\n",
    ">\n",
    "> `ks` : padding size or filter size (width == height)\n",
    "\n",
    "\n",
    "\n",
    "- `tf.pad(inputgen,[[0, 0], [ks, ks], [ks, ks], [0, 0]]`\n",
    "\n",
    "    - [number of data, image **height**, image **width**, channels]\n",
    "    \n",
    "        - do not append padding on 'number of data' (dim = 0) and 'channels' (dim = 3) $\\rightarrow$ [0, 0]\n",
    "        \n",
    "        - only append padding for image it self (<span style=\"color: blue\">height (dim = 1)</span>, <span style=\"color: red\">width (dim = 2)</span>) $\\rightarrow$ <span style=\"color: blue\">[top, bottom]</span>, <span style=\"color: red\">[left, right]</span>\n",
    "\n",
    "\n",
    "\n",
    "- `general_deconv2d(input vector, output_shape, num_filters, ...)`\n",
    "\n",
    "    - `output_shape = [batch_size,64,64,ngf*2]` : [channel, width, height, num_filters]\n",
    "    \n",
    "        - the order of shape is **reveresed** because of <span style=\"color: blue\">**conv2d_transpose**</span> (De-Conv layer)\n",
    "\n",
    "\n",
    "\n",
    "- all hidden layers use **Leaky ReLU** with factor = 0.02\n",
    "\n",
    "\n",
    "\n",
    "- **architecture**\n",
    "\n",
    "> - Padding\n",
    ">\n",
    "> - input Conv layer\n",
    ">\n",
    "> - Conv layer $\\times$ 2\n",
    ">\n",
    "> - **ResNet block $\\times$ 6**\n",
    ">\n",
    "> - De-Conv layer $\\times$ 2\n",
    ">\n",
    "> - Padding\n",
    ">\n",
    "> - Conv layer\n",
    ">\n",
    "> - Tanh Activation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator $G$ : ResNet block $\\times$ 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator_resnet_9blocks(inputgen, name=\"generator\"):\n",
    "    with tf.variable_scope(name):\n",
    "        f = 7\n",
    "        ks = 3\n",
    "        \n",
    "        pad_input = tf.pad(inputgen,[[0, 0], [ks, ks], [ks, ks], [0, 0]], \"REFLECT\")\n",
    "        o_c1 = general_conv2d(pad_input, ngf, f, f, 1, 1, 0.02,name=\"c1\")\n",
    "        o_c2 = general_conv2d(o_c1, ngf*2, ks, ks, 2, 2, 0.02,\"SAME\",\"c2\")\n",
    "        o_c3 = general_conv2d(o_c2, ngf*4, ks, ks, 2, 2, 0.02,\"SAME\",\"c3\")\n",
    "\n",
    "        o_r1 = build_resnet_block(o_c3, ngf*4, \"r1\")\n",
    "        o_r2 = build_resnet_block(o_r1, ngf*4, \"r2\")\n",
    "        o_r3 = build_resnet_block(o_r2, ngf*4, \"r3\")\n",
    "        o_r4 = build_resnet_block(o_r3, ngf*4, \"r4\")\n",
    "        o_r5 = build_resnet_block(o_r4, ngf*4, \"r5\")\n",
    "        o_r6 = build_resnet_block(o_r5, ngf*4, \"r6\")\n",
    "        o_r7 = build_resnet_block(o_r6, ngf*4, \"r7\")\n",
    "        o_r8 = build_resnet_block(o_r7, ngf*4, \"r8\")\n",
    "        o_r9 = build_resnet_block(o_r8, ngf*4, \"r9\")\n",
    "\n",
    "        o_c4 = general_deconv2d(o_r9, [batch_size,128,128,ngf*2], ngf*2, ks, ks, 2, 2, 0.02,\"SAME\",\"c4\")\n",
    "        o_c5 = general_deconv2d(o_c4, [batch_size,256,256,ngf], ngf, ks, ks, 2, 2, 0.02,\"SAME\",\"c5\")\n",
    "        o_c6 = general_conv2d(o_c5, img_layer, f, f, 1, 1, 0.02,\"SAME\",\"c6\",do_relu=False)\n",
    "\n",
    "        # Adding the tanh layer\n",
    "\n",
    "        out_gen = tf.nn.tanh(o_c6,\"t1\")\n",
    "\n",
    "\n",
    "        return out_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **constants**\n",
    "\n",
    "> `f` : input layer filter size (width == height)\n",
    ">\n",
    "> `ks` : padding size or filter size (width == height)\n",
    "\n",
    "\n",
    "        \n",
    "- **architecture**\n",
    "\n",
    "> - Padding\n",
    ">\n",
    "> - input Conv layer\n",
    ">\n",
    "> - Conv layer $\\times$ 2\n",
    ">\n",
    "> - **ResNet block $\\times$ 9**\n",
    ">\n",
    "> - De-Conv layer $\\times$ 2\n",
    ">\n",
    "> - Padding\n",
    ">\n",
    "> - Conv layer\n",
    ">\n",
    "> - Tanh Activation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator $D$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gen_discriminator(inputdisc, name=\"discriminator\"):\n",
    "    \n",
    "    with tf.variable_scope(name):\n",
    "        f = 4\n",
    "\n",
    "        o_c1 = general_conv2d(inputdisc, ndf, f, f, 2, 2, 0.02, \"SAME\", \"c1\", do_norm=False, relufactor=0.2)\n",
    "        o_c2 = general_conv2d(o_c1, ndf*2, f, f, 2, 2, 0.02, \"SAME\", \"c2\", relufactor=0.2)\n",
    "        o_c3 = general_conv2d(o_c2, ndf*4, f, f, 2, 2, 0.02, \"SAME\", \"c3\", relufactor=0.2)\n",
    "        o_c4 = general_conv2d(o_c3, ndf*8, f, f, 1, 1, 0.02, \"SAME\", \"c4\",relufactor=0.2)\n",
    "        o_c5 = general_conv2d(o_c4, 1, f, f, 1, 1, 0.02, \"SAME\", \"c5\",do_norm=False,do_relu=False)\n",
    "\n",
    "        return o_c5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **constants**\n",
    "\n",
    "> `f` : filter size (width == height)\n",
    "\n",
    "        \n",
    "- **architecture**\n",
    "\n",
    "> - input Conv layer\n",
    ">\n",
    "> - Conv layer $\\times$ 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator $D$ with patched input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_discriminator(inputdisc, name=\"discriminator\"):\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "        f= 4\n",
    "\n",
    "        patch_input = tf.random_crop(inputdisc,[1,70,70,3])\n",
    "        o_c1 = general_conv2d(patch_input, ndf, f, f, 2, 2, 0.02, \"SAME\", \"c1\", do_norm=\"False\", relufactor=0.2)\n",
    "        o_c2 = general_conv2d(o_c1, ndf*2, f, f, 2, 2, 0.02, \"SAME\", \"c2\", relufactor=0.2)\n",
    "        o_c3 = general_conv2d(o_c2, ndf*4, f, f, 2, 2, 0.02, \"SAME\", \"c3\", relufactor=0.2)\n",
    "        o_c4 = general_conv2d(o_c3, ndf*8, f, f, 2, 2, 0.02, \"SAME\", \"c4\", relufactor=0.2)\n",
    "        o_c5 = general_conv2d(o_c4, 1, f, f, 1, 1, 0.02, \"SAME\", \"c5\",do_norm=False,do_relu=False)\n",
    "\n",
    "        return o_c5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **constants**\n",
    "\n",
    "> `f` : filter size (width == height)\n",
    "\n",
    "        \n",
    "- **architecture**\n",
    "\n",
    "> - input Conv layer\n",
    ">\n",
    "> - Conv layer $\\times$ 4\n",
    "\n",
    "\n",
    "\n",
    "- `tf.random_crop(value, size)`\n",
    "\n",
    "    - value : image vector\n",
    "    \n",
    "    - size : wanted size after cropping\n",
    "    \n",
    "        - e.g. [32, 32, 3] 이미지에서 [24, 24, 3] 만큼을 자르고 싶을 때에는 size=[24, 24, 3]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import .main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `img_height = 256` : height of image\n",
    "\n",
    "- `img_width = 256` : width of image\n",
    "\n",
    "- `img_layer = 3` : channels of image\n",
    "\n",
    "- `img_size = img_height * img_width` : size of image\n",
    "\n",
    "---\n",
    "\n",
    "- `to_train = True` : check if training\n",
    "\n",
    "- `to_test = False` : check if testing\n",
    "\n",
    "- `to_restore = False` : check if training saved model continuously\n",
    "\n",
    "- `output_path = \"./output\"`\n",
    "\n",
    "- `check_dir = \"./output/checkpoints/\"`\n",
    "\n",
    "- temp_check = 0\n",
    "\n",
    "---\n",
    "\n",
    "- `max_epoch = 1`\n",
    "\n",
    "- `max_images = 100`\n",
    "\n",
    "---\n",
    "\n",
    "- `h1_size = 150` : (NOT USED)\n",
    "\n",
    "- `h2_size = 300` : (NOT USED)\n",
    "\n",
    "- `z_size = 100` : (NOT USED)\n",
    "\n",
    "- `batch_size = 1` : mini-batch size\n",
    "\n",
    "- `pool_size = 50` : number of pooling filters\n",
    "\n",
    "- `sample_size = 10` : (NOT USED)\n",
    "\n",
    "- `save_training_images = True` : check if save training images\n",
    "\n",
    "- `ngf = 32` : number of filters for generator $G$\n",
    "\n",
    "- `ndf = 64` : number of filters for discriminator $D$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class CycleGAN():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_setup(self):\n",
    "\n",
    "        filenames_A = tf.train.match_filenames_once(\"./input/horse2zebra/trainA/*.jpg\")    \n",
    "        self.queue_length_A = tf.size(filenames_A)\n",
    "        filenames_B = tf.train.match_filenames_once(\"./input/horse2zebra/trainB/*.jpg\")    \n",
    "        self.queue_length_B = tf.size(filenames_B)\n",
    "        \n",
    "        filename_queue_A = tf.train.string_input_producer(filenames_A)\n",
    "        filename_queue_B = tf.train.string_input_producer(filenames_B)\n",
    "\n",
    "        image_reader = tf.WholeFileReader()\n",
    "        _, image_file_A = image_reader.read(filename_queue_A)\n",
    "        _, image_file_B = image_reader.read(filename_queue_B)\n",
    "\n",
    "        self.image_A = tf.subtract(tf.div(tf.image.resize_images(\n",
    "            tf.image.decode_jpeg(image_file_A),[256,256]),127.5),1)\n",
    "        self.image_B = tf.subtract(tf.div(tf.image.resize_images(\n",
    "            tf.image.decode_jpeg(image_file_B),[256,256]),127.5),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> dataset ***A*** : horse image dataset\n",
    ">\n",
    "> dataset ***B*** : zebra image dataset\n",
    "\n",
    "\n",
    "\n",
    "- `tf.train.match_filenames_once(*.*)` : read all file names in specific directory with specific extension\n",
    "\n",
    "   - takes the list of all training images\n",
    "\n",
    "\n",
    "    \n",
    "- `tf.size()` : get length of the name list\n",
    "\n",
    "\n",
    "\n",
    "- `tf.io.decode_jpeg(contents, channels=0, ratio=1)` : decode a JPEG-encoded image to a uint8 tensor\n",
    "\n",
    "    - channels\n",
    "    \n",
    "        - 0 : use the number of channels in the JPEG-encoded image\n",
    "        \n",
    "        - 1 : output a grayscale image\n",
    "        \n",
    "        - 3 : output an RGB image\n",
    "        \n",
    "    - ratio : downscaling the image by an integer factor during decoding. Allowed values are: 1, 2, 4, and 8\n",
    "\n",
    "\n",
    "\n",
    "- `self.image_A` / `self.image_B` : Normalize image vector\n",
    "\n",
    "    - `tf.image.resize_images(decoded_image, [256,256])` : resize image to 256 $\\times$ 256\n",
    "    \n",
    "    - `tf.div(resized_image, 127.5)` : divide each pixel value by a half of the width (256 / 127.5 = 2)\n",
    "    \n",
    "    - `tf.subtract(divided_image, 1)` : subtract each pixel value by 1\n",
    "    \n",
    "    $\\Rightarrow$ now all pixels of the image have value **range near 1**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 GANs\n",
    "\n",
    "${L_{GAN}(G(x), y) + ||F(G(x)) - x||_{1}} + {L_{GAN}(F(y), x) + ||G(F(y)) - y||_{1}}$\n",
    "\n",
    ">- Generator 1 $G$\n",
    ">\n",
    ">    - $x$: horse\n",
    ">\n",
    ">    - $G$: horse $\\rightarrow$ zebra\n",
    ">\n",
    ">    - $G(x)$: **zebra** image generated by $G$\n",
    ">\n",
    ">\n",
    ">- Generator 2 $F$\n",
    ">\n",
    ">    - $y$: zebra\n",
    ">\n",
    ">    - $F$: zebra $\\rightarrow$ horse\n",
    ">\n",
    ">    - $F(y)$: **horse** image generated by $F$\n",
    "\n",
    "\n",
    "**[Model *A*] horse $\\rightarrow$ zebra 모델**\n",
    "\n",
    "- $G$ 가 horse 를 만들어내는 역할 (== **A**)\n",
    "    \n",
    "- $F$ 가 zebra 로 되돌리는 역할 (== **B**)\n",
    "    \n",
    "    \n",
    "**inversely...**\n",
    "\n",
    "\n",
    "**[Model *B*] zebra $\\rightarrow$ horse 모델**\n",
    "\n",
    "- $F$ 가 zebra 를 만들어내는 역할 (== **B**)\n",
    "    \n",
    "- $G$ 가 horse 로 되돌리는 역할 (== **A**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_read(self, sess):\n",
    "\n",
    "        # Loading images into the tensors\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "        num_files_A = sess.run(self.queue_length_A)\n",
    "        num_files_B = sess.run(self.queue_length_B)\n",
    "\n",
    "        self.fake_images_A = np.zeros((pool_size, 1, img_height, img_width, img_layer))\n",
    "        self.fake_images_B = np.zeros((pool_size, 1, img_height, img_width, img_layer))\n",
    "\n",
    "\n",
    "        self.A_input = np.zeros((max_images, batch_size, img_height, img_width, img_layer))\n",
    "        self.B_input = np.zeros((max_images, batch_size, img_height, img_width, img_layer))\n",
    "\n",
    "        for i in range(max_images): \n",
    "            image_tensor = sess.run(self.image_A)\n",
    "            if(image_tensor.size == img_size*batch_size*img_layer):\n",
    "                self.A_input[i] = image_tensor.reshape((batch_size, img_height, img_width, img_layer))\n",
    "\n",
    "        for i in range(max_images):\n",
    "            image_tensor = sess.run(self.image_B)\n",
    "            if(image_tensor.size == img_size*batch_size*img_layer):\n",
    "                self.B_input[i] = image_tensor.reshape((batch_size, img_height, img_width, img_layer))\n",
    "\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `self.fake_images_A` / `self.fake_images_B` : **random noise** input for generator A and B\n",
    "\n",
    "\n",
    "\n",
    "- `self.A_input` / `self.B_input` : stores all the training images in python list\n",
    "\n",
    "    - `image_tensor = sess.run(self.input)` : convert numpy array to tensor\n",
    "    \n",
    "    - `if(image_tensor.size == img_size*batch_size*img_layer)` : check the shapes are correct\n",
    "    \n",
    "    - `self.A_input[i] = image_tensor.reshape(image_shape)` : fill the tensor with an image one by one\n",
    "    \n",
    "        - individual image shape : (1, height, width, channel)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_setup(self):\n",
    "\n",
    "        self.input_A = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_layer], \n",
    "                                      name=\"input_A\")\n",
    "        self.input_B = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_layer], \n",
    "                                      name=\"input_B\")\n",
    "        \n",
    "        self.fake_pool_A = tf.placeholder(tf.float32, [None, img_width, img_height, img_layer], \n",
    "                                          name=\"fake_pool_A\")\n",
    "        self.fake_pool_B = tf.placeholder(tf.float32, [None, img_width, img_height, img_layer], \n",
    "                                          name=\"fake_pool_B\")\n",
    "\n",
    "        self.global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "\n",
    "        self.num_fake_inputs = 0\n",
    "\n",
    "        self.lr = tf.placeholder(tf.float32, shape=[], name=\"lr\")\n",
    "\n",
    "        with tf.variable_scope(\"Model\") as scope:\n",
    "            \n",
    "            self.fake_B = build_generator_resnet_9blocks(self.input_A, name=\"g_A\")\n",
    "            # fake zebra <- real horse\n",
    "            self.fake_A = build_generator_resnet_9blocks(self.input_B, name=\"g_B\")\n",
    "            # fake horse <- real zebra\n",
    "            \n",
    "            self.rec_A = build_gen_discriminator(self.input_A, \"d_A\")\n",
    "            # is this horse real or fake? <- real horse\n",
    "            self.rec_B = build_gen_discriminator(self.input_B, \"d_B\")\n",
    "            # is this zebra real or fake? <- real zebra\n",
    "\n",
    "            scope.reuse_variables()\n",
    "\n",
    "            self.fake_rec_A = build_gen_discriminator(self.fake_A, \"d_A\")\n",
    "            # is this horse real or fake? <- fake horse\n",
    "            self.fake_rec_B = build_gen_discriminator(self.fake_B, \"d_B\")\n",
    "            # is this zebra real or fake? <- fake zebra\n",
    "            \n",
    "            self.cyc_A = build_generator_resnet_9blocks(self.fake_B, \"g_B\")\n",
    "            # cycled horse <- fake zebra\n",
    "            self.cyc_B = build_generator_resnet_9blocks(self.fake_A, \"g_A\")\n",
    "            # cycled zebra <- fake horse\n",
    "\n",
    "            scope.reuse_variables()\n",
    "\n",
    "            self.fake_pool_rec_A = build_gen_discriminator(self.fake_pool_A, \"d_A\")\n",
    "            # is this horse real or fake? <- cycled horse\n",
    "            self.fake_pool_rec_B = build_gen_discriminator(self.fake_pool_B, \"d_B\")\n",
    "            # is this zebra real or fake? <- cycled zebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `self.input_A` / `self.input_B` : placeholder for training images (A: horse, B: zebra)\n",
    "\n",
    "- `self.fake_A` / `self.fake_B` : Generated images by corresponding generator of input_A ($G$) and input_B ($F$)\n",
    "\n",
    "- `self.lr` : Learning rate\n",
    "\n",
    "</br>\n",
    "\n",
    "**[Terms]**\n",
    "\n",
    "- **A** : horse\n",
    "\n",
    "    - **g_A** : generating fake zebra\n",
    "    \n",
    "    - **d_A** : discriminating horse is real\n",
    "    \n",
    "- **B** : zebra\n",
    "\n",
    "    - **g_B** : generating fake horse\n",
    "    \n",
    "    - **d_B** : discriminating zebra is real\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model A (horse $\\rightarrow$ zebra)\n",
    "\n",
    "${L_{GAN}(G(x), y) + ||F(G(x)) - x||_{1}}$ $\\Rightarrow$ ${L_{GAN}(Generated Fake Zebra, Real Zebra) + ||Cycled Horse - Real Horse||_{1}}$\n",
    ">\n",
    "> - $x$ : real horse image\n",
    ">\n",
    "> - $G$ : horse $\\rightarrow$ zebra\n",
    ">\n",
    ">     - $G(x)$ : generated fake zebra\n",
    ">\n",
    ">\n",
    "> - $F$ : zebra $\\rightarrow$ horse\n",
    ">\n",
    ">     - $F(G(x))$ : cycled (returned) horse\n",
    "\n",
    "\n",
    "1. generator $G(x)$ : **real horse** from training data $\\rightarrow$ **fake zebra**\n",
    "\n",
    "    - `self.fake_B = build_generator_resnet_9blocks(self.input_A, name=\"g_A\")`\n",
    "    \n",
    "\n",
    "2. discriminator $D(y)$ : is this **zebra real or fake** $\\leftarrow$ **real zebra**\n",
    "\n",
    "    - `self.rec_B = build_gen_discriminator(self.input_B, \"d_B\")`\n",
    "    \n",
    "\n",
    "3. discriminator $D(G(x))$ : is this **zebra real or fake** $\\leftarrow$ generated **fake zebra**\n",
    "\n",
    "    - `self.fake_rec_B = build_gen_discriminator(self.fake_B, \"d_B\")`\n",
    "    \n",
    "\n",
    "4. generator $F(G(x))$ : generated **fake zebra** $\\rightarrow$ **cycled horse**\n",
    "\n",
    "    - `self.cyc_A = build_generator_resnet_9blocks(self.fake_B, \"g_B\")`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model B (zebra $\\rightarrow$ horse)\n",
    "\n",
    "${L_{GAN}(F(y), x) + ||G(F(y)) - y||_{1}}$ $\\Rightarrow$ ${L_{GAN}(Generated Fake Horse, Real Horse) + ||Cycled Zebra - Real Zebra||_{1}}$\n",
    ">\n",
    "> - $y$ : real zebra image\n",
    ">\n",
    "> - $F$ : zebra $\\rightarrow$ horse\n",
    ">\n",
    ">     - $F(y)$ : generated fake horse\n",
    ">\n",
    ">\n",
    "> - $G$ : horse $\\rightarrow$ zebra\n",
    ">\n",
    ">     - $G(F(y))$ : cycled (returned) zebra\n",
    "\n",
    "\n",
    "1. generator $G(x)$ : **real zebra** from training data $\\rightarrow$ **fake horse**\n",
    "\n",
    "     - `self.fake_A = build_generator_resnet_9blocks(self.input_B, name=\"g_B\")`\n",
    "\n",
    "\n",
    "2. discriminator $D(y)$ : is this **horse real or fake** $\\leftarrow$ **real horse**\n",
    "\n",
    "     - `self.rec_A = build_gen_discriminator(self.input_A, \"d_A\")`\n",
    "\n",
    "\n",
    "3. discriminator $D(G(x))$ : is this **horse real or fake** $\\leftarrow$ generated **fake horse**\n",
    "\n",
    "     - `self.fake_rec_A = build_gen_discriminator(self.fake_A, \"d_A\")`\n",
    "\n",
    "\n",
    "4. generator $F(G(x))$ : generated **fake horse** $\\rightarrow$ **cycled zebra**\n",
    "\n",
    "     - `self.cyc_B = build_generator_resnet_9blocks(self.fake_A, \"g_A\")`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_calc(self):\n",
    "\n",
    "        ''' In this function we are defining the variables for loss calcultions and traning model\n",
    "        d_loss_A/d_loss_B -> loss for discriminator A/B\n",
    "        g_loss_A/g_loss_B -> loss for generator A/B\n",
    "        *_trainer -> Variaous trainer for above loss functions\n",
    "        *_summ -> Summary variables for above loss functions'''\n",
    "\n",
    "        cyc_loss = tf.reduce_mean(tf.abs(self.input_A-self.cyc_A)) + tf.reduce_mean(\n",
    "            tf.abs(self.input_B-self.cyc_B))\n",
    "        \n",
    "        disc_loss_A = tf.reduce_mean(tf.squared_difference(self.fake_rec_A,1))\n",
    "        disc_loss_B = tf.reduce_mean(tf.squared_difference(self.fake_rec_B,1))\n",
    "        \n",
    "        g_loss_A = cyc_loss*10 + disc_loss_B\n",
    "        g_loss_B = cyc_loss*10 + disc_loss_A\n",
    "\n",
    "        d_loss_A = (tf.reduce_mean(tf.square(self.fake_pool_rec_A)) + tf.reduce_mean(\n",
    "            tf.squared_difference(self.rec_A,1))) / 2.0\n",
    "        d_loss_B = (tf.reduce_mean(tf.square(self.fake_pool_rec_B)) + tf.reduce_mean(\n",
    "            tf.squared_difference(self.rec_B,1))) / 2.0\n",
    "\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(self.lr, beta1=0.5)\n",
    "\n",
    "        self.model_vars = tf.trainable_variables()\n",
    "\n",
    "        d_A_vars = [var for var in self.model_vars if 'd_A' in var.name]\n",
    "        g_A_vars = [var for var in self.model_vars if 'g_A' in var.name]\n",
    "        d_B_vars = [var for var in self.model_vars if 'd_B' in var.name]\n",
    "        g_B_vars = [var for var in self.model_vars if 'g_B' in var.name]\n",
    "        \n",
    "        self.d_A_trainer = optimizer.minimize(d_loss_A, var_list=d_A_vars)\n",
    "        self.d_B_trainer = optimizer.minimize(d_loss_B, var_list=d_B_vars)\n",
    "        self.g_A_trainer = optimizer.minimize(g_loss_A, var_list=g_A_vars)\n",
    "        self.g_B_trainer = optimizer.minimize(g_loss_B, var_list=g_B_vars)\n",
    "\n",
    "        for var in self.model_vars: print(var.name)\n",
    "\n",
    "        #Summary variables for tensorboard\n",
    "\n",
    "        self.g_A_loss_summ = tf.summary.scalar(\"g_A_loss\", g_loss_A)\n",
    "        self.g_B_loss_summ = tf.summary.scalar(\"g_B_loss\", g_loss_B)\n",
    "        self.d_A_loss_summ = tf.summary.scalar(\"d_A_loss\", d_loss_A)\n",
    "        self.d_B_loss_summ = tf.summary.scalar(\"d_B_loss\", d_loss_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least Square GANs\n",
    "\n",
    "##### **[Model A]** (horse $\\rightarrow$ zebra)\n",
    "\n",
    "$L_{GAN}(G, D_{Y}, X, Y) = E_{y \\sim P_{data}(y)}[(D_{Y}(y) - 1)^2] + E_{x \\sim P_{data}(x)}[(D_{Y}(G(x)))^2]$\n",
    "\n",
    "##### Model B (zebra $\\rightarrow$ horse)\n",
    "\n",
    "$L_{GAN}(F, D_{X}, X, Y) = E_{y \\sim P_{data}(x)}[(D_{X}(x) - 1)^2] + E_{x \\sim P_{data}(y)}[(D_{X}(F(y)))^2]$\n",
    "\n",
    "\n",
    "\n",
    "- **[`cyc_loss`]** : L1 Loss (pixel level difference)\n",
    "\n",
    "    - $||F(G(x)) - x||_{1}$\n",
    "    \n",
    "        - cycled horse $-$ real horse\n",
    "\n",
    "        - `tf.reduce_mean(tf.abs(self.input_A-self.cyc_A))`\n",
    "        \n",
    "    - $||G(F(y)) - y||_{1}$\n",
    "    \n",
    "        - cycled zebra $-$ real zebra\n",
    "        \n",
    "        - `tf.reduce_mean(tf.abs(self.input_B-self.cyc_B))`\n",
    "\n",
    "\n",
    "\n",
    "- **[`g_loss_A`]** / `g_loss_B` : Loss for **Generator** **[A ($G$)]** / B ($F$)\n",
    "\n",
    "    - $||F(G(x)) - x||_{1} + ||G(F(y)) - y||_{1}$\n",
    "    \n",
    "        - L1 Loss\n",
    "    \n",
    "        - `cyc_loss`\n",
    "\n",
    "    - $[(D_{Y}(G(x)) - 1)^2]$\n",
    "    \n",
    "        - make fake zebra image $G(x)$ be judged as real (1) as possible\n",
    "    \n",
    "        - `disc_loss_B = tf.reduce_mean(tf.squared_difference(self.fake_rec_B,1))`\n",
    "        \n",
    "\n",
    "\n",
    "- `d_loss_A` / **[`d_loss_B`]** : Loss for **Discriminator** A ($D_{X}$) / **[B ($D_{Y}$)]**\n",
    "\n",
    "    - $[D_{Y}(G(x))^2]$\n",
    "    \n",
    "        - judge fake horse image as false (0) as possible\n",
    "    \n",
    "        - `tf.reduce_mean(tf.square(self.fake_pool_rec_B))`\n",
    "        \n",
    "    - $[(D_{Y}(y) - 1)^2]$\n",
    "    \n",
    "        - judge real horse image as real (1) as possible\n",
    "    \n",
    "        - `tf.reduce_mean(tf.squared_difference(self.rec_B,1))`\n",
    "        \n",
    "---\n",
    "\n",
    "- `tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999)`\n",
    "\n",
    "    - learning_rate : A Tensor or a floating point value. The learning rate\n",
    "\n",
    "    - beta1 : The exponential decay rate for the 1st moment estimates (l1 regularization)\n",
    "\n",
    "    - beta2 : The exponential decay rate for the 2nd moment estimates (l2 regularization)\n",
    "\n",
    "\n",
    "- `tf.trainable_variables()`\n",
    "\n",
    "    - Returns all variables created with `trainable = True`\n",
    "    \n",
    "\n",
    "- `tf.summary.scalar(name, scalar)`\n",
    "\n",
    "    - Tensorboard\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_images(self, sess, epoch):\n",
    "\n",
    "        if not os.path.exists(\"./output/imgs\"):\n",
    "            os.makedirs(\"./output/imgs\")\n",
    "\n",
    "        for i in range(0,10):\n",
    "            fake_A_temp, fake_B_temp, cyc_A_temp, cyc_B_temp = sess.run(\n",
    "                [self.fake_A, self.fake_B, self.cyc_A, self.cyc_B],\n",
    "                feed_dict={self.input_A:self.A_input[i], self.input_B:self.B_input[i]})\n",
    "            imageio.imwrite(\"./output/imgs/fakeB_\"+ str(epoch) + \"_\" + str(i)+\".jpg\",\n",
    "                            ((fake_A_temp[0]+1)*127.5).astype(np.uint8))\n",
    "            imageio.imwrite(\"./output/imgs/fakeA_\"+ str(epoch) + \"_\" + str(i)+\".jpg\",\n",
    "                            ((fake_B_temp[0]+1)*127.5).astype(np.uint8))\n",
    "            imageio.imwrite(\"./output/imgs/cycA_\"+ str(epoch) + \"_\" + str(i)+\".jpg\",\n",
    "                            ((cyc_A_temp[0]+1)*127.5).astype(np.uint8))\n",
    "            imageio.imwrite(\"./output/imgs/cycB_\"+ str(epoch) + \"_\" + str(i)+\".jpg\",\n",
    "                            ((cyc_B_temp[0]+1)*127.5).astype(np.uint8))\n",
    "            imageio.imwrite(\"./output/imgs/inputA_\"+ str(epoch) + \"_\" + str(i)+\".jpg\", \n",
    "                            ((self.A_input[i][0]+1)*127.5).astype(np.uint8))\n",
    "            imageio.imwrite(\"./output/imgs/inputB_\"+ str(epoch) + \"_\" + str(i)+\".jpg\",\n",
    "                            ((self.B_input[i][0]+1)*127.5).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `os.makedirs(path)` : make save directory\n",
    "\n",
    "- `from scipy.misc import imsave`\n",
    "\n",
    "    - `imsave(path)` : save image in specific directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifying generated fake images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_image_pool(self, num_fakes, fake, fake_pool):\n",
    "\n",
    "        if(num_fakes < pool_size):\n",
    "            fake_pool[num_fakes] = fake\n",
    "            return fake\n",
    "        else :\n",
    "            p = random.random()\n",
    "            if p > 0.5:\n",
    "                random_id = random.randint(0,pool_size-1)\n",
    "                temp = fake_pool[random_id]\n",
    "                fake_pool[random_id] = fake\n",
    "                return temp\n",
    "            else :\n",
    "                return fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This function saves the generated image to corresponding pool of images.\n",
    ">\n",
    "> - It keeps filling the pool untill it is full \n",
    ">\n",
    ">     - `if(num_fakes < pool_size):`\n",
    ">\n",
    ">\n",
    "> - and then randomly selects an already stored image \n",
    ">\n",
    ">     - `p = random.random()`\n",
    ">    \n",
    ">     - `if p > 0.5:`\n",
    ">\n",
    "> - and replace it with new one\n",
    "\n",
    "- `random.randint(min, max)` : pop random value between min and max value, inclusive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self):\n",
    "\n",
    "\n",
    "''' Training Function '''\n",
    "\n",
    "\n",
    "# Load Dataset from the dataset folder\n",
    "self.input_setup()  \n",
    "\n",
    "#Build the network\n",
    "self.model_setup()\n",
    "\n",
    "#Loss function calculations\n",
    "self.loss_calc()\n",
    "\n",
    "# Initializing the global variables\n",
    "init = [tf.global_variables_initializer(), tf.local_variables_initializer()]\n",
    "saver = tf.train.Saver()     \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    #Read input to nd array\n",
    "    self.input_read(sess)\n",
    "\n",
    "    #Restore the model to run the model from last checkpoint\n",
    "    if to_restore:\n",
    "        chkpt_fname = tf.train.latest_checkpoint(check_dir)\n",
    "        saver.restore(sess, chkpt_fname)\n",
    "\n",
    "    writer = tf.summary.FileWriter(\"./output/2\")\n",
    "\n",
    "    if not os.path.exists(check_dir):\n",
    "        os.makedirs(check_dir)\n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(sess.run(self.global_step),100):                \n",
    "        print (\"In the epoch \", epoch)\n",
    "        saver.save(sess,os.path.join(check_dir,\"cyclegan\"),global_step=epoch)\n",
    "\n",
    "        # Dealing with the learning rate as per the epoch number\n",
    "\n",
    "        if(epoch < 100) :\n",
    "            curr_lr = 0.0002\n",
    "        else:\n",
    "            # learning rate decay\n",
    "            curr_lr = 0.0002 - 0.0002*(epoch-100)/100\n",
    "\n",
    "        # ------------------------------------------------------\n",
    "\n",
    "        if(save_training_images):\n",
    "            self.save_training_images(sess, epoch)\n",
    "\n",
    "        # sys.exit()\n",
    "\n",
    "        for ptr in range(0,max_images):\n",
    "            print(\"In the iteration \",ptr)\n",
    "            print(\"Starting\",time.time()*1000.0)\n",
    "\n",
    "            # Optimizing the G_A network--------------------------------------------------------------\n",
    "\n",
    "            _, fake_B_temp, summary_str = sess.run([self.g_A_trainer, self.fake_B, self.g_A_loss_summ],\n",
    "                                                   feed_dict={self.input_A:self.A_input[ptr],\n",
    "                                                              self.input_B:self.B_input[ptr], \n",
    "                                                              self.lr:curr_lr})\n",
    "\n",
    "            writer.add_summary(summary_str, epoch*max_images + ptr)                    \n",
    "            fake_B_temp1 = self.fake_image_pool(self.num_fake_inputs, fake_B_temp, self.fake_images_B)\n",
    "\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "\n",
    "            # Optimizing the D_B network--------------------------------------------------------------\n",
    "\n",
    "            _, summary_str = sess.run([self.d_B_trainer, self.d_B_loss_summ],\n",
    "                                      feed_dict={self.input_A:self.A_input[ptr], \n",
    "                                                 self.input_B:self.B_input[ptr], \n",
    "                                                 self.lr:curr_lr, \n",
    "                                                 self.fake_pool_B:fake_B_temp1})\n",
    "            writer.add_summary(summary_str, epoch*max_images + ptr)\n",
    "\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "\n",
    "            # Optimizing the G_B network--------------------------------------------------------------\n",
    "\n",
    "            _, fake_A_temp, summary_str = sess.run([self.g_B_trainer, self.fake_A, self.g_B_loss_summ],\n",
    "                                                   feed_dict={self.input_A:self.A_input[ptr],\n",
    "                                                              self.input_B:self.B_input[ptr], \n",
    "                                                              self.lr:curr_lr})\n",
    "\n",
    "            writer.add_summary(summary_str, epoch*max_images + ptr)\n",
    "\n",
    "            fake_A_temp1 = self.fake_image_pool(self.num_fake_inputs, fake_A_temp, self.fake_images_A)\n",
    "\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "\n",
    "            # Optimizing the D_A network--------------------------------------------------------------\n",
    "\n",
    "            _, summary_str = sess.run([self.d_A_trainer, self.d_A_loss_summ],\n",
    "                                      feed_dict={self.input_A:self.A_input[ptr], \n",
    "                                                 self.input_B:self.B_input[ptr], \n",
    "                                                 self.lr:curr_lr, \n",
    "                                                 self.fake_pool_A:fake_A_temp1})\n",
    "\n",
    "            writer.add_summary(summary_str, epoch*max_images + ptr)\n",
    "\n",
    "            # ----------------------------------------------------------------------------------------\n",
    "\n",
    "            self.num_fake_inputs+=1                       \n",
    "\n",
    "        sess.run(tf.assign(self.global_step, epoch + 1))\n",
    "\n",
    "    writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(self):\n",
    "\n",
    "\n",
    "    ''' Testing Function'''\n",
    "\n",
    "    print(\"Testing the results\")\n",
    "\n",
    "    self.input_setup()\n",
    "\n",
    "    self.model_setup()\n",
    "    saver = tf.train.Saver()\n",
    "    init = [tf.global_variables_initializer(), tf.local_variables_initializer()]\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        sess.run(init)\n",
    "\n",
    "        self.input_read(sess)\n",
    "\n",
    "        chkpt_fname = tf.train.latest_checkpoint(check_dir)\n",
    "        saver.restore(sess, chkpt_fname)\n",
    "\n",
    "        if not os.path.exists(\"./output/imgs/test/\"):\n",
    "            os.makedirs(\"./output/imgs/test/\")            \n",
    "\n",
    "        for i in range(0,100):\n",
    "            fake_A_temp, fake_B_temp = sess.run([self.fake_A, self.fake_B],\n",
    "                                                feed_dict={self.input_A:self.A_input[i],\n",
    "                                                           self.input_B:self.B_input[i]})\n",
    "            imageio.imwrite(\"./output/imgs/test/fakeB_\"+str(i)+\".jpg\",\n",
    "                            ((fake_A_temp[0]+1)*127.5).astype(np.uint8))\n",
    "            imageio.imwrite(\"./output/imgs/test/fakeA_\"+str(i)+\".jpg\",\n",
    "                            ((fake_B_temp[0]+1)*127.5).astype(np.uint8))\n",
    "            imageio.imwrite(\"./output/imgs/test/inputA_\"+str(i)+\".jpg\",\n",
    "                            ((self.A_input[i][0]+1)*127.5).astype(np.uint8))\n",
    "            imageio.imwrite(\"./output/imgs/test/inputB_\"+str(i)+\".jpg\",\n",
    "                            ((self.B_input[i][0]+1)*127.5).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **restore previously trained checkpoint**\n",
    "\n",
    "```python\n",
    "chkpt_fname = tf.train.latest_checkpoint(check_dir)\n",
    "saver.restore(sess, chkpt_fname)\n",
    "```\n",
    "\n",
    "- **generate fake images (desired output)**\n",
    "\n",
    "```python\n",
    "fake_A_temp, fake_B_temp = sess.run([self.fake_A, self.fake_B],\n",
    "                                    feed_dict={self.input_A:self.A_input[i],\n",
    "                                               self.input_B:self.B_input[i]})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    model = CycleGAN()\n",
    "    if to_train:\n",
    "        model.train()\n",
    "    elif to_test:\n",
    "        model.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
