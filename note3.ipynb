{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Conditional GAN 을 이용한 MNIST 숫자 생성\n",
    "\n",
    "- (ref: https://github.com/eriklindernoren/Keras-GAN/blob/master/cgan/cgan.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 학습코드\n",
    "\n",
    "```python\n",
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class CGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.num_classes = 10\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise and the target label as input\n",
    "        # and generates the corresponding digit of that label\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,))\n",
    "        img = self.generator([noise, label])\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated image as input and determines validity\n",
    "        # and the label of that image\n",
    "        valid = self.discriminator([img, label])\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model([noise, label], valid)\n",
    "        self.combined.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n",
    "\n",
    "        model_input = multiply([noise, label_embedding])\n",
    "        img = model(model_input)\n",
    "\n",
    "        return Model([noise, label], img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512, input_dim=np.prod(self.img_shape)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, np.prod(self.img_shape))(label))\n",
    "        flat_img = Flatten()(img)\n",
    "\n",
    "        model_input = multiply([flat_img, label_embedding])\n",
    "\n",
    "        validity = model(model_input)\n",
    "\n",
    "        return Model([img, label], validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, y_train), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Configure input\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs, labels = X_train[idx], y_train[idx]\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict([noise, labels])\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch([imgs, labels], valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Condition on labels\n",
    "            sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 2, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        sampled_labels = np.arange(0, 10).reshape(-1, 1)\n",
    "\n",
    "        gen_imgs = self.generator.predict([noise, sampled_labels])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n",
    "                axs[i,j].set_title(\"Digit: %d\" % sampled_labels[cnt])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cgan = CGAN()\n",
    "    cgan.train(epochs=20000, batch_size=32, sample_interval=200)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) library import\n",
    "\n",
    "`keras.layers`\n",
    "\n",
    "- keras 의 하위 모듈인 layers 에서 여러가지 method 사용가능\n",
    "\n",
    "- `Input`: keras tensor 객체 생성\n",
    "\n",
    "- `Dense`: layer 사이를 결합 (Fully-Connected)\n",
    "\n",
    "- `Reshape`: tensor 의 차원을 변형\n",
    "\n",
    "- `Flatten`: 다차원 tensor 를 1 차원으로 변환\n",
    "\n",
    "- `Dropout`: Input 에 dropout 기법 적용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import print_function, division\n",
    "\n",
    "from keras.utils import plot_model # model visualization\n",
    "from IPython.display import Image, display # model visualization\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1) declaring class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class CGAN():\n",
    "    \n",
    "    def __init__(self): # constructor\n",
    "        # Input shape\n",
    "        self.init_hyperparams()\n",
    "        self.init_discriminator()\n",
    "        self.init_generator()\n",
    "        self.init_model()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Hyper-parameter settings & Generator / Discriminator details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter settings\n",
    "\n",
    "- MNIST 이미지는 28 Pixel $\\times$ 28 Pixel 이미지\n",
    "    \n",
    "- 따라서 img_rows 와 img_cols 모두 28 이며, 흑백사진 이므로 채널은 1\n",
    "    \n",
    "- 분류해야할 클래스 (Y label) 은 0 ~ 9 총 10개\n",
    "    \n",
    "- hidden layer 은 100 개, Optimizer 는 AdamOptimizer 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def init_hyperparams(self):\n",
    "        # input data reference\n",
    "        self.img_rows = 28 # input image row size (세로)\n",
    "        self.img_cols = 28 # input image column size  (가로)\n",
    "        self.channels = 1 # black & white\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels) # shape for creating image\n",
    "        self.num_classes = 10 # Y label for 0 to 9\n",
    "        self.latent_dim = 100 \n",
    "        \n",
    "        # Adam optimizer 의 beta1 default value = 0.9\n",
    "        # beta 1 을 줄임으로써 GAN 을 학습하는 동안 generator 의 학습실패로 인해 discriminator 가 빠르게 학습하고, loss 가 0 으로 빠르게 수렴하는 현상 방지\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator details\n",
    "\n",
    "`Model.compile`: keras 에서 모델의 학습과정을 설정할때 (loss, optimizer, performance measure 등) 사용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def init_discriminator(self):\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss = ['binary_crossentropy'], optimizer = self.optimizer, metrics = ['accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator details\n",
    "\n",
    "- random noise $z$ 입력 받음\n",
    "\n",
    "- fake image $G(z)$ 를 생성\n",
    "\n",
    "- Batch_size 가 정의되지 않은경우, 자동으로 Input_Dimension 으로 인식\n",
    "\n",
    "- Batch_size 정의된 경우, Batch_size 를 인자로 먼저 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def init_generator(self):\n",
    "        self.generator = self.build_generator()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generator 학습 과정**\n",
    "\n",
    "- Generator 가 fake image 생성\n",
    "\n",
    "- Discriminator 가 real 인지 fake 인지 판별\n",
    "\n",
    "- Discriminator Loss 계산\n",
    "\n",
    "- Back Propagation\n",
    "\n",
    "> 이때 Discriminator 의 weight 가 고정된 상태에서 학습을 진행해야 하므로 `discriminator.trainable = False` 로 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def init_model(self):\n",
    "        # The generator takes noise and the target label as input\n",
    "        # and generates the corresponding digit of that label\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,))\n",
    "        img = self.generator([noise, label])\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated image as input and determines validity\n",
    "        # and the label of that image\n",
    "        valid = self.discriminator([img, label])\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model([noise, label], valid)\n",
    "        self.combined.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Building Generator\n",
    "\n",
    "- `BatchNormalization` 을 통한 정규화 수행\n",
    "\n",
    "- `np.prod()`: 주어진 axis 에 속한 element 간의 곱셈\n",
    "\n",
    "- `Flatten()(Embedding(self.num_classes, self.latent_dim)(label))`: keras 함수형 API 사용\n",
    "\n",
    "    - label 을 고차원 vector 로 Embedding 후, Flatten 해서 row vector / column vector 로 변환\n",
    "    \n",
    "    \n",
    "- noise 와 label 을 입력받고, img 를 출력 \n",
    "\n",
    "    - label = [0 or 1 or 2 ... or 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        \n",
    "        # hidden_dim (latent_dim) 100 개의 image data 를 입력받아, MNIST 형태인 (28, 28, 1) shape 의 데이터 출력\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh')) # np.prod(self.img_shape) 를 통해 MNIST data 의 shape 로 변환\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "        \n",
    "        # model visualization\n",
    "        plot_model(model, show_shapes=True, to_file='./images/generator_model.png')\n",
    "        display(Image(filename='./images/generator_model.png'))\n",
    "        \n",
    "        # noise 를 입력받아 fake img 를 생성\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n",
    "\n",
    "        model_input = multiply([noise, label_embedding])\n",
    "        img = model(model_input)\n",
    "        \n",
    "        # input: [noise, label] , output: img\n",
    "        return Model([noise, label], img)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Building Discriminator\n",
    "\n",
    "- Generator 와 대부분 비슷, but, img 와 label 을 입력받아서 validity 를 출력\n",
    "\n",
    "- input 으로는 training (real) image 또는 generated (fake) image $+$ label (conditional vector) 를 받음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```python   \n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512, input_dim=np.prod(self.img_shape)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        # model visualization\n",
    "        plot_model(model, show_shapes=True, to_file='./images/discriminator_model.png')\n",
    "        display(Image(filename='./images/discriminator_model.png'))\n",
    "        \n",
    "        # decide the image is real or fake\n",
    "        img = Input(shape=self.img_shape)\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, np.prod(self.img_shape))(label))\n",
    "        flat_img = Flatten()(img)\n",
    "\n",
    "        model_input = multiply([flat_img, label_embedding])\n",
    "\n",
    "        validity = model(model_input)\n",
    "        \n",
    "        # input: [noise, label] , output: validity\n",
    "        return Model([img, label], validity)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "    \n",
    "        # Load the dataset\n",
    "        (X_train, y_train), (_, _) = mnist.load_data()\n",
    "        \n",
    "        # Pre-processing\n",
    "        # Configure input\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5 # normalize pixel data between -1 and 1\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs, labels = X_train[idx], y_train[idx]\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict([noise, labels])\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch([imgs, labels], valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) # 두 loss 의 평균\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Condition on labels\n",
    "            sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 21s 2us/step\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (_, _) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5 # normalize pixel data between -1 and 1\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 1)\n"
     ]
    }
   ],
   "source": [
    "# 입 출력을 위한 dimension 변경\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 1)\n",
      "(128, 1)\n"
     ]
    }
   ],
   "source": [
    "# mini batch_size 크기에 맞게 valid (real) 인지 fake 인지 표기하는 vector 생성\n",
    "valid = np.ones((128, 1))\n",
    "fake = np.zeros((128, 1))\n",
    "\n",
    "print(valid.shape)\n",
    "print(fake.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47606 23704 22004 58514  2759 45937 53635 40637 10890  1643 27369 36976\n",
      " 20783 56204 10624 23077 10969 12498 35894 37360 36684 59066 39258 27719\n",
      " 20928 19963 16991 20697 26261 54622 44144 43708 10116 48971 34223 14438\n",
      "  1004 18172 39704 36804 43185 47806 17056  2300 29179 40211   840 31402\n",
      "  2414 39777 53600 52049 19028 37086 52974 34341  7643 52411 52936 16425\n",
      " 22656 15821 43182 36955   776 16546 31590 21221 34399 31536  8521 46538\n",
      "  1868 40474 27866   678 25677 22642 53394 10458 15719 21675 45518 49350\n",
      " 36285 13818 18586 44380 20374 59559 47932 57224 46634 42396 50876 36339\n",
      " 54984  6554 23552 24525 51947 32276 20192 24873 10639 55824  6780 25867\n",
      " 59366  6310 36435 58554 48632  1107  7178 30231  3380 38638 46458 32376\n",
      " 40521 43419 36078 36248 15656  5953 43859 38985]\n"
     ]
    }
   ],
   "source": [
    "# 0 ~ 60000 사이의 random value 128 개 (전체 data 에서 mini batch 만큼 뽑아냄)\n",
    "idx = np.random.randint(0, X_train.shape[0], 128)\n",
    "\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random index 값들을 이용하여 training image + y label 128 개 추출\n",
    "imgs, labels = X_train[idx], y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.58379212  1.19624084 -1.20898531 ...,  0.76103456 -1.82739536\n",
      "   2.88477641]\n",
      " [-1.03133211  0.98240722 -0.83367039 ..., -1.30040165 -1.21974368\n",
      "  -1.12502016]\n",
      " [ 1.55537176 -0.54177673 -0.23494343 ...,  1.27145743 -0.95070008\n",
      "  -1.20083224]\n",
      " ..., \n",
      " [ 0.71016121  1.65677287 -0.29513291 ..., -0.03858801  1.6586306\n",
      "   0.32300721]\n",
      " [ 0.00393512  0.40952971  0.03341764 ..., -1.47282468 -1.84854556\n",
      "   0.69204356]\n",
      " [ 0.15155601  0.47499252  1.09881113 ..., -0.91022374  0.14220695\n",
      "  -0.85010822]]\n",
      "(128, 100)\n"
     ]
    }
   ],
   "source": [
    "# generator 에 입력으로 들어갈 random noise 생성\n",
    "# shape (128, 100) <- (batch_size, flattened_image_shape)\n",
    "noise = np.random.normal(0, 1, (128, 100))\n",
    "\n",
    "print(noise)\n",
    "print(noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator 가 noise 와 label (condition) 을 입력받아 fake image 생성\n",
    "gen_imgs = self.generator.predict([noise, labels])\n",
    "\n",
    "# Train the discriminator\n",
    "# 최소 판별 정확도는 각각 0.5 (random choice)\n",
    "d_loss_real = self.discriminator.train_on_batch([imgs, labels], valid) # real image 는 valid\n",
    "d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake) # fake image 는 fake 로 학습\n",
    "\n",
    "d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) # 두 loss 의 평균"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 ~ 9 사이의 sample label (condition) 128 개 추출\n",
    "sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1) # -1 : 정해지지 않음을 뜻함\n",
    "\n",
    "print(sampled_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise 와 sample label 을 입력받아, discriminator 에게 valid 판결을 받는것을 목표로 학습 (deceiving discriminator)\n",
    "g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If at save interval => save generated image samples\n",
    "if epoch % sample_interval == 0:\n",
    "    self.sample_images(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) generator 가 생성한 이미지 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 2, 5 \n",
    "        noise = np.random.normal(0, 1, (r * c, 100)) # 0 ~ 9 클래스 10개, random noise 100개\n",
    "        sampled_labels = np.arange(0, 10).reshape(-1, 1) # 0 ~ 9 y label\n",
    "        \n",
    "        # generator 로 예측 이미지 생성\n",
    "        gen_imgs = self.generator.predict([noise, sampled_labels])\n",
    "\n",
    "        # Rescale images between 0 and 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        # matplotlib 을 사용해 vector 를 image 로 변환\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n",
    "                axs[i,j].set_title(\"Digit: %d\" % sampled_labels[cnt])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        plt.savefig(\"./images/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CGAN 객체 생성후 모델 트레이닝 실행\n",
    "cgan = CGAN()\n",
    "cgan.train(epochs = 20001, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google colab\n",
    "\n",
    "- google drive directory mount 필수\n",
    "\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "```\n",
    "...\n",
    "\n",
    "- 이미지 저장할 위치 directory 잘 보고 설정할 것\n",
    "\n",
    "```python\n",
    "def sample_images(self, epoch):\n",
    "    plt.savefig(\"/gdrive/My Drive/Colab Notebooks/.../images/%d.png\" % epoch)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.utils import plot_model # model visualization\n",
    "from IPython.display import Image, display # model visualization\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class CGAN():\n",
    "    def __init__(self):\n",
    "        self.init_hyperparams()\n",
    "        self.init_discriminator()\n",
    "        self.init_generator()\n",
    "        self.init_model()\n",
    "    \n",
    "    def init_hyperparams(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.num_classes = 10\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        self.optimizer = Adam(0.0002, 0.5)\n",
    "    \n",
    "    def init_discriminator(self):\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=['binary_crossentropy'], optimizer=self.optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    def init_generator(self):\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "    \n",
    "    def init_model(self):\n",
    "        # The generator takes noise and the target label as input\n",
    "        # and generates the corresponding digit of that label\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,))\n",
    "        img = self.generator([noise, label])\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False ### 모델을 번갈아가며 순서대로 학습 (하나 고정, 나머지 하나 학습)\n",
    "\n",
    "        # The discriminator takes generated image as input and determines validity\n",
    "        # and the label of that image\n",
    "        valid = self.discriminator([img, label])\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model([noise, label], valid)\n",
    "        \n",
    "        self.combined.summary()\n",
    "        \n",
    "        self.combined.compile(loss=['binary_crossentropy'], optimizer=self.optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "        \n",
    "        plot_model(model, show_shapes=True, to_file='generator_model.png')\n",
    "        display(Image(filename='generator_model.png'))\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n",
    "\n",
    "        model_input = multiply([noise, label_embedding])\n",
    "        img = model(model_input)\n",
    "\n",
    "        return Model([noise, label], img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512, input_dim=np.prod(self.img_shape)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        plot_model(model, show_shapes=True, to_file='discriminator_model.png')\n",
    "        display(Image(filename='discriminator_model.png'))\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, np.prod(self.img_shape))(label))\n",
    "        flat_img = Flatten()(img)\n",
    "\n",
    "        model_input = multiply([flat_img, label_embedding])\n",
    "\n",
    "        validity = model(model_input)\n",
    "\n",
    "        return Model([img, label], validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, y_train), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Configure input\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs, labels = X_train[idx], y_train[idx]\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict([noise, labels])\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch([imgs, labels], valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Condition on labels\n",
    "            sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)\n",
    "\n",
    "            # Plot the progress\n",
    "#             print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 2, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        sampled_labels = np.arange(0, 10).reshape(-1, 1)\n",
    "\n",
    "        gen_imgs = self.generator.predict([noise, sampled_labels])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n",
    "                axs[i,j].set_title(\"Digit: %d\" % sampled_labels[cnt])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "                \n",
    "        if epoch%4000 == 0:\n",
    "            plt.show()\n",
    "            \n",
    "        plt.savefig(\"./%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cgan = CGAN()\n",
    "    cgan.train(epochs=20000, batch_size=32, sample_interval=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
